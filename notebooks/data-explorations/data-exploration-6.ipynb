{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Animal, Vegetable or Machine Learning\n",
    "\n",
    "## Datasets\n",
    "  * [V&A](https://collections.vam.ac.uk/)\n",
    "  * [BBC Archive](https://www.bbc.co.uk/archive/)\n",
    "  * [CIFAR100 Training Data](https://www.cs.toronto.edu/~kriz/cifar.html) - See [Exposing AI](https://exposing.ai/) project for the ethics around image training sets.\n",
    "\n",
    "## Libraries\n",
    "\n",
    "  * [Pandas](https://pandas.pydata.org/)\n",
    "  * [Tensorflow](https://www.tensorflow.org/)\n",
    "  * [Keras](https://keras.io/)\n",
    "  * [AutoKeras](https://autokeras.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animal, Vegetable or Mineral is a basic form of classification that has a [long history](https://www.linnean.org/), and inevitably in the UK, a panel show, that has featured the  V&A collections, as can be seen in this [recording](https://www.bbc.co.uk/iplayer/episode/p017ggk3/animal-vegetable-mineral-011019) from the BBC television show of the same name from 1958. In that show the panellists were challenged to identify the following objects:\n",
    "\n",
    "  * [Swedish Padlock](https://collections.vam.ac.uk/item/O380127/padlock-unknown/)\n",
    "  * Peruvian Doll\n",
    "  * [Hanukkah Lamp](https://collections.vam.ac.uk/item/O72424/hanukkah-lamp-unknown/)\n",
    "  * [Watch](https://collections.vam.ac.uk/item/O114502/watch-jean-pattru/)\n",
    "  * Acupuncture Doll (from the [Royal College of Surgeons Collection](https://www.rcseng.ac.uk/museums-and-archives/hunterian-museum/about-us/collections/)\n",
    "  * Axe Sheath\n",
    "  * [Spoon](https://collections.vam.ac.uk/item/O109114/spoon-unknown/)\n",
    "  * [Candle Mould](https://collections.vam.ac.uk/item/O120039/candle-mould/)\n",
    "  \n",
    "Let's see if some (very simple) machine (learning) can do better than the humans on the objects featured in the show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "\n",
    "First we need to build the model, using a training dataset from [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html). This has 10 broad classifications and 100 more detailed ones within those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "This step will take some time, and ideally should be run for a *much* longer time than carried out here to get better results. This exmaple is not a real indication of the quality of human or machine learning. For a real introduction to machine learning, see the million guides on the internet for this (perhaps start with the [Keras](https://keras.io/) website.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode=\"fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./image_classifier/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./image_classifier/tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 3.8205 - accuracy: 0.1388\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 2.7901 - accuracy: 0.3161\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 2.4320 - accuracy: 0.3895\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 2.1853 - accuracy: 0.4420\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.9980 - accuracy: 0.4805\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "amv_classifier = ak.ImageClassifier(max_trials=2)\n",
    "amv_classifier.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifications in the CIFAR100 training set are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar100_broad_classes = [\n",
    "\"beaver\", \"dolphin\", \"otter\", \"seal\", \"whale\", \n",
    "\"aquarium fish\", \"flatfish\", \"ray\", \"shark\", \"trout\", \n",
    "\"orchids\", \"poppies\", \"roses\", \"sunflowers\", \"tulips\", \n",
    "\"bottles\", \"bowls\", \"cans\", \"cups\", \"plates\", \n",
    "\"apples\", \"mushrooms\", \"oranges\", \"pears\", \"sweet peppers\", \n",
    "\"clock\", \"computer keyboard\", \"lamp\", \"telephone\", \"television\", \n",
    "\"bed\", \"chair\", \"couch\", \"table\", \"wardrobe\", \n",
    "\"bee\", \"beetle\", \"butterfly\", \"caterpillar\", \"cockroach\", \n",
    "\"bear\", \"leopard\", \"lion\", \"tiger\", \"wolf\", \n",
    "\"bridge\", \"castle\", \"house\", \"road\", \"skyscraper\", \n",
    "\"cloud\", \"forest\", \"mountain\", \"plain\", \"sea\", \n",
    "\"camel\", \"cattle\", \"chimpanzee\", \"elephant\", \"kangaroo\", \n",
    "\"fox\", \"porcupine\", \"possum\", \"raccoon\", \"skunk\", \n",
    "\"crab\", \"lobster\", \"snail\", \"spider\", \"worm\", \n",
    "\"baby\", \"boy\", \"girl\", \"man\", \"woman\", \n",
    "\"crocodile\", \"dinosaur\", \"lizard\", \"snake\", \"turtle\", \n",
    "\"hamster\", \"mouse\", \"rabbit\", \"shrew\", \"squirrel\", \n",
    "\"maple\", \"oak\", \"palm\", \"pine\", \"willow\", \n",
    "\"bicycle\", \"bus\", \"motorcycle\", \"pickup truck\", \"train\", \n",
    "\"lawn-mower\", \"rocket\", \"streetcar\", \"tank\", \"tractor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks the only one we can try is the 'Hanukkah lamp'. This is another indication that this is not a very suitable test of machine learning in this example, and a training set more designed for cultural heritage object classification would perform much better (perhaps someone is working on this training set somewhere). Anyway, let's see what we get from it. First we need to convert our object image into the right matrix size to match the neural network inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "req = requests.get(\"https://api.vam.ac.uk/v2/object/O72424\")\n",
    "lamp = req.json()\n",
    "lamp_thumbnail_url = lamp['meta']['images']['_primary_thumbnail']\n",
    "response = requests.get(lamp_thumbnail_url, stream=True)\n",
    "img_array = None\n",
    "img = Image.open(response.raw)\n",
    "img = img.convert('RGB')\n",
    "img = img.resize((32,32), Image.NEAREST)\n",
    "img_array = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Now we have the image to test, we can feed it into the classifier trained on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f537c4e4b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Object has class television\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = amv_classifier.predict(np.array([img_array]))\n",
    "print(f\"Object has class {cifar100_broad_classes[int(predictions[0][0])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object has class television\n"
     ]
    }
   ],
   "source": [
    "print(f\"Object has class {cifar100_broad_classes[int(predictions[0][0])]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, well, not quite, but at least it's broadly in the right area ('household electrical items'). Let's take a look at what the algorithm was seeing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(array_to_img(img_array))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the training set's idea of a lamp is something rather different than this, so a television isn't such an unusual guess. It's likely more model training would not really affect the predicitions, as the key issue here is the training data not really being applicable to rare cultural heritage objects (a huge clue to that being in the broad group name of 'household electrical items' for a C16th lamp). But with enough examples of objects from multiple collections in a cultural heritage training dataset, there could be some improvements in the predictions for some of the items on the Animal, Vegatable or Mineral dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Victory for Humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
